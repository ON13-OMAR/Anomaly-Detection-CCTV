{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5c2a74e-a7d9-474b-b9dd-0c03099a64e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (8.3.114)\n",
      "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from ultralytics) (3.9.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from ultralytics) (10.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from ultralytics) (2.6.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from ultralytics) (0.21.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from ultralytics) (4.66.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
      "Requirement already satisfied: filelock in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gaming store\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64004bd5-9a48-4565-85b9-5715c81f59ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from ultralytics import YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc675daa-fec7-4d28-b3b7-9eee18205b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCTV Anomaly Detection System\n",
      "-----------------------------\n",
      "All required packages are installed.\n",
      "\n",
      "Available video files in current directory:\n",
      "1. 4.0-39.0.mp4\n",
      "2. Footage of jewellery store robbery.mp4\n",
      "\n",
      "Select video source:\n",
      "1. Use webcam\n",
      "2. Enter video file path\n",
      "3. Use one of the listed videos\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice (1/2/3):  3\n",
      "Enter video number (1-2):  1\n",
      "Enter frame processing interval (or press Enter for default 15):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting detection with settings:\n",
      "- Video source: 4.0-39.0.mp4\n",
      "- Output directory: output\n",
      "- Frame interval: 3\n",
      "\n",
      "Starting detection...\n",
      "Loading YOLO model...\n",
      "YOLO model loaded successfully!\n",
      "Initialization complete. Processing video: 4.0-39.0.mp4\n",
      "Video details: 640x360, 30.0 FPS, 1011 total frames\n",
      "Processing: 0.0% complete | Frame 0/1011 | Time: 0.0s\n",
      "Processing: 3.0% complete | Frame 30/1011 | Time: 0.6s\n",
      "Processing: 5.9% complete | Frame 60/1011 | Time: 1.0s\n",
      "Processing: 8.9% complete | Frame 90/1011 | Time: 1.4s\n",
      "Processing: 11.9% complete | Frame 120/1011 | Time: 1.8s\n",
      "Processing: 14.8% complete | Frame 150/1011 | Time: 2.2s\n",
      "Processing: 17.8% complete | Frame 180/1011 | Time: 2.6s\n",
      "Processing: 20.8% complete | Frame 210/1011 | Time: 3.1s\n",
      "Processing: 23.7% complete | Frame 240/1011 | Time: 3.6s\n",
      "Processing: 26.7% complete | Frame 270/1011 | Time: 4.2s\n",
      "Processing: 29.7% complete | Frame 300/1011 | Time: 4.8s\n",
      "Processing: 32.6% complete | Frame 330/1011 | Time: 5.5s\n",
      "Processing: 35.6% complete | Frame 360/1011 | Time: 6.2s\n",
      "Processing: 38.6% complete | Frame 390/1011 | Time: 7.0s\n",
      "Processing: 41.5% complete | Frame 420/1011 | Time: 7.9s\n",
      "ALERT: Person 4 loitering for 5.0 seconds\n",
      "Processing: 44.5% complete | Frame 450/1011 | Time: 8.9s\n",
      "Processing: 47.5% complete | Frame 480/1011 | Time: 10.0s\n",
      "Processing: 50.4% complete | Frame 510/1011 | Time: 11.2s\n",
      "Processing: 53.4% complete | Frame 540/1011 | Time: 12.6s\n",
      "Processing: 56.4% complete | Frame 570/1011 | Time: 14.3s\n",
      "Processing: 59.3% complete | Frame 600/1011 | Time: 16.1s\n",
      "Processing: 62.3% complete | Frame 630/1011 | Time: 18.0s\n",
      "Processing: 65.3% complete | Frame 660/1011 | Time: 20.2s\n",
      "Processing: 68.2% complete | Frame 690/1011 | Time: 22.4s\n",
      "Processing: 71.2% complete | Frame 720/1011 | Time: 24.9s\n",
      "Processing: 74.2% complete | Frame 750/1011 | Time: 27.4s\n",
      "Processing: 77.2% complete | Frame 780/1011 | Time: 30.2s\n",
      "Processing: 80.1% complete | Frame 810/1011 | Time: 33.1s\n",
      "Processing: 83.1% complete | Frame 840/1011 | Time: 36.0s\n",
      "ALERT: Person 7 loitering for 5.0 seconds\n",
      "Processing: 86.1% complete | Frame 870/1011 | Time: 39.2s\n",
      "Processing: 89.0% complete | Frame 900/1011 | Time: 42.3s\n",
      "Processing: 92.0% complete | Frame 930/1011 | Time: 45.5s\n",
      "Processing: 95.0% complete | Frame 960/1011 | Time: 48.7s\n",
      "Processing: 97.9% complete | Frame 990/1011 | Time: 52.0s\n",
      "End of video file reached.\n",
      "Video processing completed in 54.27 seconds.\n",
      "Output saved to: output\\output.mp4\n",
      "Total people detected: 10\n",
      "Total loitering alerts: 2\n"
     ]
    }
   ],
   "source": [
    " class CCTVAnomalyDetection:\n",
    "    def __init__(self, video_source=0, output_dir=\"output\", frame_interval=15, use_webcam=False):\n",
    "        self.video_source = video_source\n",
    "        self.output_dir = output_dir\n",
    "        self.frame_interval = frame_interval\n",
    "        self.use_webcam = use_webcam\n",
    "\n",
    "        \n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "       \n",
    "        print(\"Loading YOLO model...\")\n",
    "        self.yolo_model = YOLO(\"yolov8n.pt\")\n",
    "        print(\"YOLO model loaded successfully!\")\n",
    "\n",
    "        \n",
    "        self.people_tracks = defaultdict(list)\n",
    "        self.next_person_id = 0\n",
    "        self.loitering_time_threshold = 5  \n",
    "        self.loitering_distance_threshold = 50  \n",
    "        self.loitering_alerts = []\n",
    "\n",
    "        \n",
    "        self.detection_history = []\n",
    "        self.anomaly_frames = []\n",
    "        self.colors = {}\n",
    "        \n",
    "        if use_webcam:\n",
    "            print(f\"Initialization complete. Using webcam as video source.\")\n",
    "        else:\n",
    "            print(f\"Initialization complete. Processing video: {video_source}\")\n",
    "\n",
    "    def _detect_people(self, frame):\n",
    "        try:\n",
    "            \n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            \n",
    "            results = self.yolo_model.predict(source=rgb_frame, imgsz=416, conf=0.5, verbose=False)\n",
    "\n",
    "            people = []\n",
    "            for result in results:\n",
    "                for box in result.boxes:\n",
    "                    cls = int(box.cls[0])\n",
    "                    conf = float(box.conf[0])\n",
    "                    # Class 0 is person in COCO dataset\n",
    "                    if cls == 0 and conf > 0.5:\n",
    "                        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                        \n",
    "                        x = max(0, x1)\n",
    "                        y = max(0, y1)\n",
    "                        w = min(frame.shape[1] - x, x2 - x1)\n",
    "                        h = min(frame.shape[0] - y, y2 - y1)\n",
    "                        if w > 0 and h > 0:\n",
    "                            people.append({\n",
    "                                'bbox': (x, y, w, h),\n",
    "                                'center': (x + w//2, y + h//2)\n",
    "                            })\n",
    "            return people\n",
    "        except Exception as e:\n",
    "            print(f\"YOLOv8 detection error: {e}\")\n",
    "            return []\n",
    "\n",
    "    def _get_color_for_id(self, person_id):\n",
    "        if person_id not in self.colors:\n",
    "            self.colors[person_id] = tuple(np.random.randint(0, 255, 3).tolist())\n",
    "        return self.colors[person_id]\n",
    "\n",
    "    def _track_people(self, people, timestamp):\n",
    "        if not people:\n",
    "            return\n",
    "\n",
    "        \n",
    "        if not any(self.people_tracks.values()):\n",
    "            for person in people:\n",
    "                self.people_tracks[self.next_person_id].append({\n",
    "                    'center': person['center'],\n",
    "                    'bbox': person['bbox'],\n",
    "                    'timestamp': timestamp\n",
    "                })\n",
    "                self.next_person_id += 1\n",
    "            return\n",
    "\n",
    "      \n",
    "        unmatched_people = list(range(len(people)))\n",
    "        tracked_ids = list(self.people_tracks.keys())\n",
    "\n",
    "        for track_id in tracked_ids:\n",
    "            last_detection = self.people_tracks[track_id][-1]\n",
    "            last_center = last_detection['center']\n",
    "            min_dist = float('inf')\n",
    "            match_idx = None\n",
    "\n",
    "          \n",
    "            for i in unmatched_people:\n",
    "                curr_center = people[i]['center']\n",
    "                dist = np.linalg.norm(np.array(curr_center) - np.array(last_center))\n",
    "                if dist < min_dist and dist < 100:  \n",
    "                    min_dist = dist\n",
    "                    match_idx = i\n",
    "\n",
    "          \n",
    "            if match_idx is not None:\n",
    "                self.people_tracks[track_id].append({\n",
    "                    'center': people[match_idx]['center'],\n",
    "                    'bbox': people[match_idx]['bbox'],\n",
    "                    'timestamp': timestamp\n",
    "                })\n",
    "                unmatched_people.remove(match_idx)\n",
    "\n",
    "    \n",
    "        for idx in unmatched_people:\n",
    "            self.people_tracks[self.next_person_id].append({\n",
    "                'center': people[idx]['center'],\n",
    "                'bbox': people[idx]['bbox'],\n",
    "                'timestamp': timestamp\n",
    "            })\n",
    "            self.next_person_id += 1\n",
    "\n",
    "    def _draw_tracking_trail(self, frame, person_id, max_length=20):\n",
    "        if person_id not in self.people_tracks:\n",
    "            return frame\n",
    "            \n",
    "        \n",
    "        detections = self.people_tracks[person_id][-max_length:]\n",
    "        color = self._get_color_for_id(person_id)\n",
    "        \n",
    "      \n",
    "        for i in range(1, len(detections)):\n",
    "            cv2.line(frame, detections[i - 1]['center'], detections[i]['center'], color, 2)\n",
    "            \n",
    "        return frame\n",
    "\n",
    "    def _detect_loitering(self, current_time):\n",
    "        loiterers = []\n",
    "        for person_id, detections in self.people_tracks.items():\n",
    "            \n",
    "            if len(detections) < 5:\n",
    "                continue\n",
    "                \n",
    "            \n",
    "            duration = current_time - detections[0]['timestamp']\n",
    "            \n",
    "            if duration >= self.loitering_time_threshold:\n",
    "         \n",
    "                centers = [d['center'] for d in detections]\n",
    "                max_distance = max(np.linalg.norm(np.array(c1) - np.array(c2)) \n",
    "                                   for i, c1 in enumerate(centers) \n",
    "                                   for c2 in centers[i+1:])\n",
    "                                   \n",
    "                if max_distance < self.loitering_distance_threshold:\n",
    "                    loiterers.append({\n",
    "                        'person_id': person_id,\n",
    "                        'bbox': detections[-1]['bbox'],\n",
    "                        'duration': duration\n",
    "                    })\n",
    "                    \n",
    "                    \n",
    "                    if person_id not in [a['person_id'] for a in self.loitering_alerts]:\n",
    "                        self.loitering_alerts.append({\n",
    "                            'person_id': person_id,\n",
    "                            'timestamp': current_time,\n",
    "                            'location': detections[-1]['center'],\n",
    "                            'duration': duration\n",
    "                        })\n",
    "                        print(f\"ALERT: Person {person_id} loitering for {duration:.1f} seconds\")\n",
    "                        \n",
    "        return loiterers\n",
    "\n",
    "    def _add_info_panel(self, frame):\n",
    "        \"\"\"Add an information panel with detection stats\"\"\"\n",
    "        h, w = frame.shape[:2]\n",
    "        panel_height = 70\n",
    "        panel = np.zeros((panel_height, w, 3), dtype=np.uint8)\n",
    "        \n",
    "      \n",
    "        cv2.rectangle(panel, (0, 0), (w, panel_height), (50, 50, 50), -1)\n",
    "        \n",
    "      \n",
    "        active_tracks = len(self.people_tracks)\n",
    "        loitering_count = len([a for a in self.loitering_alerts \n",
    "                              if a['person_id'] in self.people_tracks])\n",
    "                              \n",
    "        cv2.putText(panel, f\"Active Tracks: {active_tracks}\", (10, 25), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200, 200, 200), 2)\n",
    "        cv2.putText(panel, f\"Loitering Alerts: {loitering_count}\", (250, 25), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (50, 50, 255), 2)\n",
    "        cv2.putText(panel, f\"Total Persons Detected: {self.next_person_id}\", (10, 55), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200, 200, 200), 2)\n",
    "        \n",
    "        \n",
    "        result = np.vstack([panel, frame])\n",
    "        return result\n",
    "\n",
    "    def process_video(self):\n",
    "        \n",
    "        cap = cv2.VideoCapture(self.video_source)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Error opening video source: {self.video_source}\")\n",
    "            return False\n",
    "\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        if self.use_webcam:\n",
    "            fps = 30  \n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        \n",
    "        if self.use_webcam:\n",
    "            total_frames = float('inf')  \n",
    "            print(f\"Webcam started: {width}x{height} at {fps} FPS\")\n",
    "        else:\n",
    "            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            print(f\"Video details: {width}x{height}, {fps} FPS, {total_frames} total frames\")\n",
    "\n",
    "        \n",
    "        out_path = os.path.join(self.output_dir, \"output.mp4\")\n",
    "        out = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height + 70))\n",
    "\n",
    "        frame_count = 0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                if self.use_webcam:\n",
    "                    print(\"Error reading from webcam. Attempting to reconnect...\")\n",
    "                    cap = cv2.VideoCapture(self.video_source)\n",
    "                    if not cap.isOpened():\n",
    "                        print(\"Failed to reconnect to webcam. Exiting.\")\n",
    "                        break\n",
    "                    continue\n",
    "                else:\n",
    "                    print(\"End of video file reached.\")\n",
    "                    break\n",
    "\n",
    "            process_this_frame = (frame_count % self.frame_interval == 0) if not self.use_webcam else True\n",
    "            \n",
    "            if process_this_frame:\n",
    "                current_time = time.time() - start_time if self.use_webcam else frame_count / fps\n",
    "                \n",
    "                \n",
    "                if not self.use_webcam and frame_count % (self.frame_interval * 10) == 0:\n",
    "                    elapsed = time.time() - start_time\n",
    "                    progress = frame_count / total_frames * 100\n",
    "                    print(f\"Processing: {progress:.1f}% complete | Frame {frame_count}/{total_frames} | Time: {elapsed:.1f}s\")\n",
    "                \n",
    "                \n",
    "                people = self._detect_people(frame)\n",
    "                self.detection_history.append(len(people))\n",
    "                \n",
    "                \n",
    "                self._track_people(people, current_time)\n",
    "                \n",
    "                \n",
    "                loiterers = self._detect_loitering(current_time)\n",
    "\n",
    "            \n",
    "                for person_id in self.people_tracks:\n",
    "                    frame = self._draw_tracking_trail(frame, person_id)\n",
    "\n",
    "               \n",
    "                for person in people:\n",
    "                    x, y, w, h = person['bbox']\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "                \n",
    "                for l in loiterers:\n",
    "                    x, y, w, h = l['bbox']\n",
    "                    color = (0, 0, 255)  \n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), color, 3)\n",
    "                    cv2.putText(frame, f\"Loitering: {l['duration']:.1f}s\", (x, y - 10), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "               \n",
    "                frame_with_panel = self._add_info_panel(frame)\n",
    "                \n",
    "               \n",
    "                out.write(frame_with_panel)\n",
    "                \n",
    "                \n",
    "                display_frame = frame_with_panel\n",
    "                if width > 1280:\n",
    "                    scale = 1280 / width\n",
    "                    display_frame = cv2.resize(frame_with_panel, (int(width * scale), int((height + 70) * scale)))\n",
    "                \n",
    "                cv2.imshow(\"CCTV Anomaly Detection\", display_frame)\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if key == ord('q'):\n",
    "                    print(\"Quitting - 'q' key pressed\")\n",
    "                    break\n",
    "                elif key == ord('s') and self.use_webcam:\n",
    "                    \n",
    "                    snapshot_path = os.path.join(self.output_dir, f\"snapshot_{time.strftime('')}.jpg\")\n",
    "                    cv2.imwrite(snapshot_path, frame)\n",
    "                    print(f\"Snapshot saved to {snapshot_path}\")\n",
    "\n",
    "            frame_count += 1\n",
    "\n",
    "   \n",
    "        end_time = time.time()\n",
    "        processing_time = end_time - start_time\n",
    "        \n",
    "        cap.release()\n",
    "        out.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        print(f\"Video processing completed in {processing_time:.2f} seconds.\")\n",
    "        print(f\"Output saved to: {out_path}\")\n",
    "        print(f\"Total people detected: {self.next_person_id}\")\n",
    "        print(f\"Total loitering alerts: {len(self.loitering_alerts)}\")\n",
    "        \n",
    "        return True\n",
    "\n",
    "def check_requirements():\n",
    "    \"\"\"Check if all required libraries are installed\"\"\"\n",
    "    try:\n",
    "        import cv2\n",
    "        import numpy\n",
    "        from ultralytics import YOLO\n",
    "        print(\"All required packages are installed.\")\n",
    "        return True\n",
    "    except ImportError as e:\n",
    "        print(f\"Missing requirement: {e}\")\n",
    "        print(\"Please install required packages with: pip install opencv-python numpy ultralytics\")\n",
    "        return False\n",
    "\n",
    "def list_sample_videos():\n",
    "    \"\"\"Check for sample videos in the current directory\"\"\"\n",
    "    video_extensions = ['.mp4', '.avi', '.mov', '.mkv']\n",
    "    sample_videos = []\n",
    "    \n",
    "    for file in os.listdir('.'):\n",
    "        if any(file.lower().endswith(ext) for ext in video_extensions):\n",
    "            sample_videos.append(file)\n",
    "            \n",
    "    return sample_videos\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"CCTV Anomaly Detection System\")\n",
    "    print(\"-----------------------------\")\n",
    "    \n",
    "   \n",
    "    if not check_requirements():\n",
    "        exit(1)\n",
    "    \n",
    "    \n",
    "    sample_videos = list_sample_videos()\n",
    "    if sample_videos:\n",
    "        print(\"\\nAvailable video files in current directory:\")\n",
    "        for i, video in enumerate(sample_videos, 1):\n",
    "            print(f\"{i}. {video}\")\n",
    "    else:\n",
    "        print(\"\\nNo video files found in the current directory.\")\n",
    "    \n",
    "    \n",
    "    print(\"\\nSelect video source:\")\n",
    "    print(\"1. Use webcam\")\n",
    "    print(\"2. Enter video file path\")\n",
    "    if sample_videos:\n",
    "        print(\"3. Use one of the listed videos\")\n",
    "    \n",
    "    choice = input(\"Enter your choice (1/2/3): \")\n",
    "    \n",
    "    use_webcam = False\n",
    "    video_source = None\n",
    "    \n",
    "    if choice == '1':\n",
    "        use_webcam = True\n",
    "        video_source = 0  \n",
    "        \n",
    "   \n",
    "        test_cam = cv2.VideoCapture(0)\n",
    "        if test_cam.isOpened():\n",
    "            test_cam.release()\n",
    "            cam_choice = input(\"Enter webcam index (0 for default, or try 1,2,etc. for other cameras): \")\n",
    "            try:\n",
    "                video_source = int(cam_choice)\n",
    "            except ValueError:\n",
    "                print(\"Invalid input. Using default webcam (0).\")\n",
    "                video_source = 0\n",
    "    elif choice == '2':\n",
    "        video_path = input(\"Enter complete path to video file: \")\n",
    "        if os.path.exists(video_path):\n",
    "            video_source = video_path\n",
    "        else:\n",
    "            print(f\"Error: File '{video_path}' not found!\")\n",
    "            exit(1)\n",
    "    elif choice == '3' and sample_videos:\n",
    "        try:\n",
    "            idx = int(input(f\"Enter video number (1-{len(sample_videos)}): \")) - 1\n",
    "            if 0 <= idx < len(sample_videos):\n",
    "                video_source = sample_videos[idx]\n",
    "            else:\n",
    "                print(\"Invalid selection. Exiting.\")\n",
    "                exit(1)\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Exiting.\")\n",
    "            exit(1)\n",
    "    else:\n",
    "        print(\"Invalid choice. Exiting.\")\n",
    "        exit(1)\n",
    "        \n",
    "    output_dir = \"output\"\n",
    "    \n",
    "    \n",
    "    frame_interval = 1 if use_webcam else 15\n",
    "    if not use_webcam:\n",
    "        try:\n",
    "            interval_input = input(\"Enter frame processing interval (or press Enter for default 15): \")\n",
    "            if interval_input:\n",
    "                frame_interval = int(interval_input)\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Using default frame interval of 15.\")\n",
    "            frame_interval = 15\n",
    "    \n",
    "    print(f\"\\nStarting detection with settings:\")\n",
    "    if use_webcam:\n",
    "        print(f\"- Video source: Webcam (index {video_source})\")\n",
    "    else:\n",
    "        print(f\"- Video source: {video_source}\")\n",
    "    print(f\"- Output directory: {output_dir}\")\n",
    "    print(f\"- Frame interval: {frame_interval}\")\n",
    "    \n",
    "    if use_webcam:\n",
    "        print(\"\\nControls:\")\n",
    "        print(\"- Press 'q' to quit\")\n",
    "        print(\"- Press 's' to save a snapshot\")\n",
    "    \n",
    "    print(\"\\nStarting detection...\")\n",
    "    \n",
    "    try:\n",
    "        detector = CCTVAnomalyDetection(video_source, output_dir, frame_interval, use_webcam)\n",
    "        success = detector.process_video()\n",
    "        if not success:\n",
    "            print(\"\\nDetection failed. Please try again with a different video source.\")\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nOperation cancelled by user.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError running the detector: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c275711-6159-493a-b769-26f85ce36256",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
